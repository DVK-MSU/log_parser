{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress control summ\n",
      "Input log files: 93. See them in C:\\Users\\Admin\\Python_M\\DVK\\streamlit_projects\\etl_microsoft_internet_info\\log_files\n",
      "Output csv files: 93. See them in C:\\Users\\Admin\\Python_M\\DVK\\streamlit_projects\\etl_microsoft_internet_info\\out_csv_logs\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "\n",
    "# >>>Extract block\n",
    "\n",
    "input_dir_with_logs = r\"C:\\Users\\Admin\\Python_M\\DVK\\streamlit_projects\\etl_microsoft_internet_info\\log_files\"\n",
    "output_dir_with_csv = r\"C:\\Users\\Admin\\Python_M\\DVK\\streamlit_projects\\etl_microsoft_internet_info\\out_csv_logs\"\n",
    "\n",
    "list_logs = os.listdir(input_dir_with_logs)\n",
    "print(\"Progress control summ\")\n",
    "print(f\"Input log files: {len(list_logs)}. See them in {input_dir_with_logs}\")\n",
    "\n",
    "for i in list_logs:\n",
    "    path_to_log = f\"{input_dir_with_logs}\\{i}\"\n",
    "\n",
    "    name_out = f'{output_dir_with_csv}\\{i.replace(\".log\", \".csv\")}'\n",
    "\n",
    "    with open(file=path_to_log, mode=\"r\") as text_in_log:\n",
    "        parsed_log = []\n",
    "        for line in text_in_log:\n",
    "\n",
    "            parsed_log.append(line.replace(\"\\n\", \"\").split(sep=\" \"))\n",
    "\n",
    "    text_in_log.close()\n",
    "\n",
    "    # <<<\n",
    "\n",
    "    # >>>Transformation block\n",
    "    def col_names():\n",
    "        # getting field names\n",
    "\n",
    "        field_names = []\n",
    "        for i in parsed_log[3]:\n",
    "            if i[0] != \"#\":\n",
    "\n",
    "                field_names.append(\n",
    "                    i.replace(\"\\n\", \"\")\n",
    "                    .replace(\"(\", \"_\")\n",
    "                    .replace(\")\", \"_\")\n",
    "                    .replace(\"-\", \"_\")\n",
    "                )\n",
    "            else:\n",
    "                pass\n",
    "        return field_names\n",
    "\n",
    "    prepeared_data = []\n",
    "    for i in parsed_log:\n",
    "        if i[0] not in [\"#Software:\", \"#Version:\", \"#Date:\", \"#Fields:\"]:\n",
    "            prepeared_data.append(i)\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(columns=col_names(), data=prepeared_data)\n",
    "\n",
    "        #date transformation type\n",
    "        \n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        # <<<\n",
    "\n",
    "        # >>> Loading block\n",
    "\n",
    "        df.to_csv(name_out, sep=\";\", index=False)\n",
    "\n",
    "        # <<<\n",
    "    except ValueError:\n",
    "        print(f\"Impossible transform log-file \\n{path_to_log}\\nto pandas DataFrame\")\n",
    "list_output_csv = os.listdir(output_dir_with_csv)\n",
    "print(f\"Output csv files: {len(list_output_csv)}. See them in {output_dir_with_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "df_u_ex091024_copy_csv\n",
      "df_u_ex091024_csv\n",
      "df_u_ex091025_csv\n",
      "df_u_ex091102_csv\n",
      "df_u_ex091103_csv\n",
      "df_u_ex091106_csv\n",
      "df_u_ex091120_csv\n",
      "df_u_ex091123_csv\n",
      "df_u_ex091207_csv\n",
      "df_u_ex091211_csv\n",
      "df_u_ex091213_csv\n",
      "df_u_ex100104_csv\n",
      "df_u_ex100105_csv\n",
      "df_u_ex100106_csv\n",
      "df_u_ex100112_csv\n",
      "df_u_ex100113_csv\n",
      "df_u_ex100117_csv\n",
      "df_u_ex100131_csv\n",
      "df_u_ex100204_csv\n",
      "df_u_ex100205_csv\n",
      "df_u_ex100221_csv\n",
      "df_u_ex100302_csv\n",
      "df_u_ex100304_csv\n",
      "df_u_ex100307_csv\n",
      "df_u_ex100309_csv\n",
      "df_u_ex100314_csv\n",
      "df_u_ex100315_csv\n",
      "df_u_ex100322_csv\n",
      "df_u_ex100406_csv\n",
      "df_u_ex100419_csv\n",
      "df_u_ex100422_csv\n",
      "df_u_ex100423_csv\n",
      "df_u_ex100424_csv\n",
      "df_u_ex100425_csv\n",
      "df_u_ex100430_csv\n",
      "df_u_ex100519_csv\n",
      "df_u_ex100520_csv\n",
      "df_u_ex100526_csv\n",
      "df_u_ex100528_csv\n",
      "df_u_ex100612_csv\n",
      "df_u_ex100615_csv\n",
      "df_u_ex100619_csv\n",
      "df_u_ex100622_csv\n",
      "df_u_ex100626_csv\n",
      "df_u_ex100628_csv\n",
      "df_u_ex100629_csv\n",
      "df_u_ex100630_csv\n",
      "df_u_ex100705_csv\n",
      "df_u_ex100708_csv\n",
      "df_u_ex100714_csv\n",
      "18\n",
      "df_u_ex100718_csv\n",
      "df_u_ex100725_csv\n",
      "df_u_ex100801_csv\n",
      "df_u_ex100808_csv\n",
      "df_u_ex100809_csv\n",
      "df_u_ex100830_csv\n",
      "df_u_ex100906_csv\n",
      "df_u_ex100912_csv\n",
      "df_u_ex100916_csv\n",
      "df_u_ex100923_csv\n",
      "df_u_ex100924_csv\n",
      "df_u_ex100926_csv\n",
      "df_u_ex101008_csv\n",
      "df_u_ex101020_csv\n",
      "df_u_ex101023_csv\n",
      "df_u_ex101025_csv\n",
      "df_u_ex101027_csv\n",
      "df_u_ex101031_csv\n",
      "df_u_ex101101_csv\n",
      "df_u_ex101111_csv\n",
      "df_u_ex101113_csv\n",
      "df_u_ex101118_csv\n",
      "df_u_ex101126_csv\n",
      "df_u_ex101202_csv\n",
      "df_u_ex101212_csv\n",
      "df_u_ex101215_csv\n",
      "df_u_ex101223_csv\n",
      "df_u_ex101225_csv\n",
      "df_u_ex110119_csv\n",
      "df_u_ex110130_csv\n",
      "df_u_ex110205_csv\n",
      "df_u_ex110209_csv\n",
      "df_u_ex110212_csv\n",
      "df_u_ex110218_csv\n",
      "df_u_ex110306_csv\n",
      "df_u_ex110405_csv\n",
      "df_u_ex110407_csv\n",
      "df_u_ex110411_csv\n",
      "df_u_ex110424_csv\n",
      "df_u_ex110427_csv\n",
      "df_u_ex110504_csv\n",
      "df_u_ex110510_csv\n",
      "df_u_ex110516_csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['df_u_ex110516_csv']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверка однотипности данных для последующего объединения\n",
    "count_fields = []\n",
    "for i in list_output_csv:\n",
    "    \n",
    "    path_to_csv = f'{output_dir_with_csv}\\{i}'\n",
    "    temp_df = pd.read_csv(path_to_csv, sep=';')\n",
    "    count_fields.append(len(temp_df.columns))\n",
    "count_series = pd.Series(count_fields)\n",
    "unique_counts = count_series.unique().tolist()\n",
    "unique_counts\n",
    "\n",
    "for j in unique_counts:\n",
    "    print(j)\n",
    "    for i in list_output_csv:\n",
    "        path_to_csv = f'{output_dir_with_csv}\\{i}'\n",
    "        temp_df = pd.read_csv(path_to_csv, sep=';')\n",
    "        if j == len(temp_df.columns):\n",
    "            df_names = []\n",
    "            df_names.append(f'df_{i.replace(\".\", \"_\").replace(\" \", \"_\")}') \n",
    "            print(df_names[0])\n",
    "            \n",
    "df_names   \n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
